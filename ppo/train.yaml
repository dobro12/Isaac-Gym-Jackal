name: PPO

activation: 'ReLU'
hidden_dims: [256, 256]
log_std_init: 0.0
max_grad_norm: 1.0
value_lr: 0.0003
policy_lr: 0.001

discount_factor: 0.99
value_epochs: 100
policy_epochs: 20
clip_value: 0.05
gae_coeff: 0.97
ent_coeff: 0.0
max_kl: 0.01